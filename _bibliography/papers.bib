---
---
@String { ACMMM        = {Proceedings of the ACM International Conference on Multimedia} }
@String { ARXIV        = {arXiv} }
@String { BMVC         = {Proceedings of the British Machine Vision Conference} }
@String { CVPR         = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition} }
@String { ECCV         = {Proceedings of the European Conference on Computer Vision.} }
@String { ICASSP       = {Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing} }
@String { ICCP         = {Proceedings of the IEEE International Conference on Computational Photography} }
@String { ICCV         = {Proceedings of the IEEE/CVF International Conference on Computer Vision} }
@String { ICIP         = {Proceedings of the IEEE International Conference on Image Processing} }
@String { ICLR         = {Proceedings of the International Conference on Learning Representations} }
@String { ICME         = {Proceedings of the IEEE International Conference on Multimedia and Expo} }
@String { ICML         = {Proceedings of the International Conference on Machine Learning} }
@String { ICDM         = {Proceedings of the International Conference on Data Mining} }
@String { ICDMW         = {Proceedings of the International Conference on Data Mining Workshops} }
@String { ICMLW         = {Proceedings of the International Conference on Machine Learning Workshop} }
@String { ACL        = {Proceedings of the Annual Meeting of the Association for Computational Linguistics} }
@String { ICPR         = {International Conference on Pattern Recognition} } 
@String { IJCV         = {Int. J. Comput. Vis.} }
@String { NIPS         = {Proceedings of the Conference on Neural Information Processing Systems} }
@String { NIPSW        = {Proceedings of the International Conference on Neural Information Processing Systems Workshop} }
@String { TPAMI         = {IEEE Transactions on Pattern Analysis and Machine Intelligence} }
@String { TNNLS        = {IEEE Transactions on Neural Networks and Learning Systems}}
@String { PR           = {Pattern Recognition} }
@String { TIP          = {IEEE Transactions on Image Processing} }
@String { TMM          = {IEEE Transactions on Multimedia} }
@String { TIT          = {IEEE Transactions on Information Theory} }
@String { WACV         = {Proceedings of the IEEE Winter Conference on Applications of Computer Vision}}
@String { SPL         = {IEEE Signal Processing Letters}}
@String { AAAI         = {Proceedings of the AAAI Conference on Artificial Intelligence}}
@String { IJCAI         = {Proceedings of the International Joint Conference on Artificial Intelligence}}
@String { WWW        = {Proceedings of the Web Conference}}
@String { TOIS        = {ACM Transactions on Information Systems}}
@String { TKDD        = {ACM Transactions on Knowledge Discovery from Data}}
@String { TKDE        = {IEEE Transactions on Knowledge and Data Engineering}}
@String { ICDE        = {Proceedings of the IEEE Conference on Data Engineering}}
@String { CIKM        = {Proceedings of the International Conference on Information and Knowledge Management}}
@String { WSDM       = {Proceedings of the International Conference on Web Search and Data Mining}}
@String { TOMM        = {ACM Transactions on Multimedia Computing, Communications, and Applications}}
@String { SIGIR        = {Proceedings of the International ACM SIGIR Conference on Research \& Development in Information Retrieval}}
@String { WSDM       = {Proceedings of the International ACM Conference on Web Search \& Data Mining}}
@String { KDD        = {Proceedings of the International ACM SIGKDD Conference on Knowledge Discovery \& Data Mining}}
@String { KDDW        = {Proceedings of the International ACM SIGKDD Conference on Knowledge Discovery \& Data Mining Workshop}}
@String { VLDB       = {Proceedings of the International Conference on Very Large Data Bases}}
@String { TCVST       = {IEEE Transactions on Circuits and Systems for Video Technology}}
@String { EMNLP       = {Proceedings of the Conference on Empirical Methods in Natural Language Processing }}
@String { AISTATS      = {Proceedings of the International Conference on Artificial Intelligence and Statistics}}
@String { SDM      = {Proceedings of the SIAM International Conference on Data Mining}}

@article{qin2023diffusion,
  title    = {A Diffusion model for POI recommendation},
  author   = {Qin, Yifang and Wu, Hongjun and Ju, Wei and Luo, Xiao and Zhang, Ming},
  journal  = {ACM Transactions on Information Systems},
  url      = {http://dx.doi.org/10.1145/3624475},
  html     = {https://arxiv.org/abs/2304.07041},
  doi      = {10.1145/3624475},
  abstract = {Next Point-of-Interest (POI) recommendation is a critical task in location-based services that aim to provide personalized suggestions for the user's next destination. Previous works on POI recommendation have laid focused on modeling the user's spatial preference. However, existing works that leverage spatial information are only based on the aggregation of users' previous visited positions, which discourages the model from recommending POIs in novel areas. This trait of position-based methods will harm the model's performance in many situations. Additionally, incorporating sequential information into the user's spatial preference remains a challenge. In this paper, we propose Diff-POI: a Diffusion-based model that samples the user's spatial preference for the next POI recommendation. Inspired by the wide application of diffusion algorithm in sampling from distributions, Diff-POI encodes the user's visiting sequence and spatial character with two tailor-designed graph encoding modules, followed by a diffusion-based sampling strategy to explore the user's spatial visiting trends. We leverage the diffusion process and its reversed form to sample from the posterior distribution and optimized the corresponding score function. We design a joint training and inference framework to optimize and evaluate the proposed Diff-POI. Extensive experiments on four real-world POI recommendation datasets demonstrate the superiority of our Diff-POI over state-of-the-art baseline methods. Further ablation and parameter studies on Diff-POI reveal the functionality and effectiveness of the proposed diffusion-based sampling strategy for addressing the limitations of existing methods.},
  year     = {2023},
  selected = {true}
}

@inproceedings{10.1145/3539597.3570408,
  author    = {Qin, Yifang and Wang, Yifan and Sun, Fang and Ju, Wei and Hou, Xuyang and Wang, Zhe and Cheng, Jia and Lei, Jun and Zhang, Ming},
  title     = {DisenPOI: Disentangling Sequential and Geographical Influence for Point-of-Interest Recommendation},
  year      = {2023},
  isbn      = {9781450394079},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3539597.3570408},
  doi       = {10.1145/3539597.3570408},
  abstract  = {Point-of-Interest (POI) recommendation plays a vital role in various location-aware services. It has been observed that POI recommendation is driven by both sequential and geographical influences. However, since there is no annotated label of the dominant influence during recommendation, existing methods tend to entangle these two influences, which may lead to sub-optimal recommendation performance and poor interpretability. In this paper, we address the above challenge by proposing DisenPOI, a novel Disentangled dual-graph framework for POI recommendation, which jointly utilizes sequential and geographical relationships on two separate graphs and disentangles the two influences with self-supervision. The key novelty of our model compared with existing approaches is to extract disentangled representations of both sequential and geographical influences with contrastive learning. To be specific, we construct a geographical graph and a sequential graph based on the check-in sequence of a user. We tailor their propagation schemes to become sequence-/geo-aware to better capture the corresponding influences. Preference proxies are extracted from check-in sequence as pseudo labels for the two influences, which supervise the disentanglement via a contrastive loss. Extensive experiments on three datasets demonstrate the superiority of the proposed model.},
  booktitle = {Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining},
  pages     = {508â€“516},
  numpages  = {9},
  keywords  = {disentangled representation learning, POI recommendation, graph neural networks},
  location  = {Singapore, Singapore},
  series    = {WSDM '23},
  pdf       = {WSDM_23.pdf},
  selected  = {true}
}


@article{10138449,
  author  = {Luo, Xiao and Zhao, Yusheng and Qin, Yifang and Ju, Wei and Zhang, Ming},
  journal = {IEEE Transactions on Knowledge and Data Engineering},
  title   = {Towards Semi-supervised Universal Graph Classification},
  year    = {2023},
  volume  = {},
  number  = {},
  pages   = {1-13},
  doi     = {10.1109/TKDE.2023.3280859}
}

@inproceedings{10096088,
  author    = {Yuan, Jingyang and Luo, Xiao and Qin, Yifang and Zhao, Yusheng and Ju, Wei and Zhang, Ming},
  booktitle = {ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  title     = {Learning on Graphs under Label Noise},
  year      = {2023},
  volume    = {},
  number    = {},
  pages     = {1-5},
  doi       = {10.1109/ICASSP49357.2023.10096088}
}

@article{Ju_Gu_Chen_Sun_Qin_Liu_Luo_Zhang_2023,
  title    = {GLCC: A General Framework for Graph-Level Clustering},
  volume   = {37},
  url      = {https://ojs.aaai.org/index.php/AAAI/article/view/25559},
  doi      = {10.1609/aaai.v37i4.25559},
  abstract = {This paper studies the problem of graph-level clustering, which is a novel yet challenging task. This problem is critical in a variety of real-world applications such as protein clustering and genome analysis in bioinformatics. Recent years have witnessed the success of deep clustering coupled with graph neural networks (GNNs). However, existing methods focus on clustering among nodes given a single graph, while exploring clustering on multiple graphs is still under-explored. In this paper, we propose a general graph-level clustering framework named Graph-Level Contrastive Clustering (GLCC) given multiple graphs. Specifically, GLCC first constructs an adaptive affinity graph to explore instance- and cluster-level contrastive learning (CL). Instance-level CL leverages graph Laplacian based contrastive loss to learn clustering-friendly representations while cluster-level CL captures discriminative cluster representations incorporating neighbor information of each sample. Moreover, we utilize neighbor-aware pseudo-labels to reward the optimization of representation learning. The two steps can be alternatively trained to collaborate and benefit each other. Experiments on a range of well-known datasets demonstrate the superiority of our proposed GLCC over competitive baselines.},
  number   = {4},
  journal  = {Proceedings of the AAAI Conference on Artificial Intelligence},
  author   = {Ju, Wei and Gu, Yiyang and Chen, Binqi and Sun, Gongbo and Qin, Yifang and Liu, Xingyuming and Luo, Xiao and Zhang, Ming},
  year     = {2023},
  month    = {Jun.},
  pages    = {4391-4399}
}

@inproceedings{10027744,
  author    = {Ju, Wei and Qin, Yifang and Qiao, Ziyue and Luo, Xiao and Wang, Yifan and Fu, Yanjie and Zhang, Ming},
  booktitle = {2022 IEEE International Conference on Data Mining (ICDM)},
  title     = {Kernel-based Substructure Exploration for Next POI Recommendation},
  year      = {2022},
  volume    = {},
  number    = {},
  pages     = {221-230},
  doi       = {10.1109/ICDM54844.2022.00032},
  html      = {https://ieeexplore.ieee.org/abstract/document/10027744},
  pdf       = {ICDM_2022.pdf},
  selected  = {true}
}

@inproceedings{10.1007/978-3-031-26387-3_29,
  author    = {Wang, Yifan
               and Qin, Yifang
               and Han, Yu
               and Yin, Mingyang
               and Zhou, Jingren
               and Yang, Hongxia
               and Zhang, Ming},
  editor    = {Amini, Massih-Reza
               and Canu, St{\'e}phane
               and Fischer, Asja
               and Guns, Tias
               and Kralj Novak, Petra
               and Tsoumakas, Grigorios},
  title     = {AD-AUG: Adversarial Data Augmentation forÂ Counterfactual Recommendation},
  booktitle = {Machine Learning and Knowledge Discovery in Databases},
  year      = {2023},
  publisher = {Springer International Publishing},
  address   = {Cham},
  pages     = {474--490},
  abstract  = {Collaborative filtering (CF) has become one of the most popular and widely used methods in recommender systems, but its performance degrades sharply in practice due to the sparsity and bias of the real-world user feedback data. In this paper, we propose a novel counterfactual data augmentation framework AD-AUG to mitigate the impact of the imperfect training data and empower CF models. The key idea of AD-AUG is to answer the counterfactual question: ``what would be a user's feedback if his previous purchase history had been different?''. Our framework is composed of an augmenter model and a recommender model. The augmenter model aims to generate counterfactual user feedback based on the observed ones, while the recommender leverages the original and counterfactual user feedback data to provide the final recommendation. In particular, we design two adversarial learning-based methods from both ``bottom-up'' data-oriented and ``top-down'' model-oriented perspectives for counterfactual learning. Extensive experiments on three real-world datasets show that the AD-AUG can greatly enhance a wide range of CF models, demonstrating our framework's effectiveness and generality.},
  isbn      = {978-3-031-26387-3},
  html      = {https://link.springer.com/chapter/10.1007/978-3-031-26387-3_29},
  pdf       = {ECML_2022.pdf},
  selected  = {true}
}



@inproceedings{10.1145/3477495.3531851,
  author    = {Wang, Yifan and Qin, Yifang and Sun, Fang and Zhang, Bo and Hou, Xuyang and Hu, Ke and Cheng, Jia and Lei, Jun and Zhang, Ming},
  title     = {DisenCTR: Dynamic Graph-Based Disentangled Representation for Click-Through Rate Prediction},
  year      = {2022},
  isbn      = {9781450387323},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3477495.3531851},
  doi       = {10.1145/3477495.3531851},
  abstract  = {Click-through rate (CTR) prediction plays a critical role in recommender systems and other applications. Recently, modeling user behavior sequences attracts much attention and brings great improvements in the CTR field. Many existing works utilize attention mechanism or recurrent neural networks to exploit user interest from the sequence, but fail to recognize the simple truth that a user's real-time interests are inherently diverse and fluid. In this paper, we propose DisenCTR, a novel dynamic graph-based disentangled representation framework for CTR prediction. The key novelty of our method compared with existing approaches is to model evolving diverse interests of users. Specifically, we construct a time-evolving user-item interaction graph induced by historical interactions. And based on the rich dynamics supplied by the graph, we propose a disentangled graph representation module to extract diverse user interests. We further exploit the fluidity of user interests and model the temporal effect of historical behaviors using Mixture of Hawkes Process. Extensive experiments on three real-world datasets demonstrate the superior performance of our method comparing to state-of-the-art approaches.},
  booktitle = {Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages     = {2314â€“2318},
  numpages  = {5},
  keywords  = {graph neural networks, disentangled representation learning, ctr prediction},
  location  = {Madrid, Spain},
  series    = {SIGIR '22},
  html = {https://dl.acm.org/doi/10.1145/3477495.3531851},
  pdf = {SIGIR_2022.pdf},
  selected  = {true}
}


@article{JU2023122,
  title    = {Few-shot Molecular Property Prediction via Hierarchically Structured Learning on Relation Graphs},
  journal  = {Neural Networks},
  volume   = {163},
  pages    = {122-131},
  year     = {2023},
  issn     = {0893-6080},
  doi      = {https://doi.org/10.1016/j.neunet.2023.03.034},
  url      = {https://www.sciencedirect.com/science/article/pii/S0893608023001685},
  author   = {Wei Ju and Zequn Liu and Yifang Qin and Bin Feng and Chen Wang and Zhihui Guo and Xiao Luo and Ming Zhang},
  keywords = {Molecular property prediction, Few-shot learning, Graph neural networks, Meta learning},
  abstract = {This paper studies few-shot molecular property prediction, which is a fundamental problem in cheminformatics and drug discovery. More recently, graph neural network based model has gradually become the theme of molecular property prediction. However, there is a natural deficiency for existing methods, that is, the scarcity of molecules with desired properties, which makes it hard to build an effective predictive model. In this paper, we propose a novel framework called Hierarchically Structured Learning on Relation Graphs (HSL-RG) for molecular property prediction, which explores the structural semantics of a molecule from both global-level and local-level granularities. Technically, we first leverage graph kernels to construct relation graphs to globally communicate molecular structural knowledge from neighboring molecules and then design self-supervised learning signals of structure optimization to locally learn transformation-invariant representations from molecules themselves. Moreover, we propose a task-adaptive meta-learning algorithm to provide meta knowledge customization for different tasks in few-shot scenarios. Experiments on multiple real-life benchmark datasets show that HSL-RG is superior to existing state-of-the-art approaches.}
}
